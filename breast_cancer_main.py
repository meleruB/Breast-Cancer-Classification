# -*- coding: utf-8 -*-
"""breast-cancer-Main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cGjavNHTOwfukADexfVTqwqdtTo9HeJE
"""

!pip install interpret
!pip install --user xgboost
!pip install pytorch-
!pip install lime

!pip install pytorch-tabnet

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from interpret import preserve, show
import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

random_state=42

#Setul de date Breast Cancer Wisconsin Diagnostic a fost încărcat cu ajutorul bibliotecii scikit-learn, prin funcția load_breast_cancer().
#Informațiile, inițial stocate ca array-uri NumPy, au fost transformate într-un DataFrame Pandas,
#combinând variabilele explicative (cancer['data']) cu vectorul țintă (cancer['target']) și atribuind denumiri corespunzătoare coloanelor.
from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()
df = pd.DataFrame(np.c_[cancer['data'], cancer['target']],
                  columns= np.append(cancer['feature_names'], ['target']))
df.target = df.target.astype(np.int64)
_class = 'target'
class_names = [0, 1]

df.head()

df.info()

X, y = df.drop(columns=[_class]), df[_class]

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=random_state)

x_test.shape

"""# EDA"""

data = x_train
corr = data.corr()
# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype=bool))
# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))
ax = sns.heatmap(
    corr, mask=mask,
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n=200),
    square=True,  cbar_kws={"shrink": .5}
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
);

x_train.info()

"""# ML Model"""

import sklearn.metrics
import pandas as pd
import time
import numpy as np

from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
import xgboost as xgb
from interpret.glassbox import ExplainableBoostingClassifier
from pytorch_tabnet.tab_model import TabNetClassifier

random_state=42

x_train

def classify_report(clfs, dataset):
    x_train, y_train, x_test, y_test = dataset
    data = []
    for clf, name, no_df in clfs:
        if no_df:
            x_tr, x_te = x_train, x_test
        else:
            x_tr, x_te = x_train.values,  x_test.values
        clf.fit(x_tr, y_train)
        pred = clf.predict(x_te)
        f1, acc = sklearn.metrics.f1_score(y_test, pred, average='binary'), sklearn.metrics.accuracy_score(y_test, pred)
        data.append([name, f1, acc])
    df = pd.DataFrame(data, columns = ['Name', 'F1', 'Acc.'])
    df = df.sort_values(by=['F1'])
    return df

from sklearn.model_selection import GridSearchCV
from scipy.stats import randint

# Initialize the RandomForestClassifier
rf = RandomForestClassifier(random_state=42)

# Define the hyperparameters grid
param_grid = {
    'n_estimators': [15, 25, 50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 10, 15, 20],
    'min_samples_leaf': [1, 4, 8],
    'bootstrap': [False]
}

# Initialize the GridSearchCV with training data only
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)

# Fit the grid search to the training data
grid_search.fit(x_train, y_train)

# Print the best parameters and best score from training data
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Training Score: {grid_search.best_score_}")

from sklearn.metrics import accuracy_score
# Evaluate the best model on the test data
# best_rf = grid_search.best_estimator_
best_rf = RandomForestClassifier(**grid_search.best_params_, random_state=random_state)
best_rf.fit(x_train, y_train)
y_pred = best_rf.predict(x_test)
# Calculate accuracy on test data
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Set Accuracy: {accuracy}")

rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=random_state)
gbc = GradientBoostingClassifier(random_state=random_state)
_xgb = xgb.XGBClassifier(random_state=random_state)
ebm = ExplainableBoostingClassifier(random_state=random_state)
tbn = TabNetClassifier(verbose=0, seed=random_state)

clfs = [(rf, 'rf', True), (gbc, 'gbc', True), (_xgb, 'xgb', True), (ebm, 'ebm', True), (tbn, 'tbn', False)]
# clfs = [(rf, 'rf', True), (ebm, 'ebm', True), (tbn, 'tbn', False)]
dataset = x_train, y_train, x_test, y_test
classify_report(clfs, dataset)

"""# XAI"""

# selected_model = _xgb
# For fairness of comparisions we used RF
selected_model = rf

import time, datetime
from joblib import Parallel, delayed
import itertools

n_jobs = 8

class_names = ['NO','YES']
feature_names = x_train.columns.to_list()
# local = lime, shap, anchor, tabnet, ebm
# global = pfi, tabnet, ebm, shap
# methods = pfi, tabnet, ebm, shap, lime, anchor
# remaining = pdp, eli5, ice, adawhip, break down

"""## Local

### LIME
"""

import lime
from lime import lime_tabular

exp_lime=lime_tabular.LimeTabularExplainer(np.array(x_train),feature_names=x_train.columns,class_names=['NO','YES'],mode='classification')

def lime_explain_instance_step(i, lim):
    warnings.filterwarnings("ignore")
    out = []
    for k in range(i, lim):
        e = exp_lime.explain_instance(x_test.values[k], selected_model.predict_proba)
        out.append(e)
    return out

# lime_explanations_list = [exp_lime.explain_instance(x_test.values[i], selected_model.predict_proba) for i in range(len(x_test))]  # sequential and slower
total = len(x_test)
out = Parallel(n_jobs=n_jobs)(delayed(lime_explain_instance_step)(i, min(total, i+int(total/n_jobs))) for i in range(0, total, int(total/n_jobs)))
lime_explanations_list = list(itertools.chain(*out))

display(x_test.iloc[2:4])
display(y_test.iloc[2:4])

id_to_explain = 2
lime_explanations_list[id_to_explain].show_in_notebook(show_table=True)

id_to_explain = 3
lime_explanations_list[id_to_explain].show_in_notebook(show_table=True)

"""### SHAP"""

import shap
shap.plots.initjs()

exp_shap = shap.TreeExplainer(selected_model)
shap_values = exp_shap.shap_values(x_test)

shap_html = shap.force_plot(exp_shap.expected_value[0],
                            shap_values[id_to_explain][:, 0],
                            x_test.iloc[id_to_explain],
                            matplotlib=True)

exp_shap_values = exp_shap(x_test)

# print(exp_shap.expected_value + sum(shap_values[3]))
print(exp_shap.expected_value[0] + sum(shap_values[3][:, 0]))
print(selected_model.predict_proba(x_test)[3, 0])

id_to_explain = 2
output_to_explain = 0

# shap.plots.waterfall(exp_shap_values[id_to_explain], max_display=10)
shap.plots.waterfall(exp_shap_values[id_to_explain,:,output_to_explain], max_display=10)

id_to_explain = 3
output_to_explain = 1
# shap.plots.waterfall(exp_shap_values[id_to_explain], max_display=10)
shap.plots.waterfall(exp_shap_values[id_to_explain,:,output_to_explain], max_display=10)

"""#### Fidelity"""

selected_model_predict_proba_array = selected_model.predict_proba(x_test)
selected_model_predict_array = selected_model.predict(x_test)

id_to_test = 3
print('LIME', selected_model_predict_proba_array[id_to_test, 1], lime_explanations_list[id_to_test].local_pred[0])
print(int(lime_explanations_list[id_to_test].local_pred[0]>0.5))
print('SHAP', selected_model_predict_proba_array[id_to_test, 1], exp_shap.expected_value[1] + np.sum(shap_values[id_to_test][:, 1]))
print(int(exp_shap.expected_value[1] + np.sum(shap_values[id_to_test][:, 1])>0.5))
del id_to_test

lime_fidelity = np.mean([1-np.abs(selected_model_predict_proba_array[i, 1] - (lime_explanations_list[i].local_pred[0])) for i in range(len(x_test))])
print(f'LIME Fidelity: {lime_fidelity:.4f}')

# For SHAP, fidelity is usually high as it's designed to be an accurate representation of the model
shap_fidelity = np.mean([1-np.abs(selected_model_predict_proba_array[i, 1] - (exp_shap.expected_value[1] + np.sum(shap_values[i][:, 1]))) for i in range(len(x_test))])
print(f'SHAP Fidelity: {shap_fidelity:.4f}')

# accuracy_score(selected_model.predict(X_test), np.argmax(shap_values, axis=1))
from sklearn.metrics import accuracy_score

lime_predict_array = np.array([int(lime_explanations_list[i].local_pred[0]>0.5) for i in range(len(x_test))])
shap_predict_array = np.array([int(exp_shap.expected_value[1] + np.sum(shap_values[i][:, 1])>0.5) for i in range(len(x_test))])

print(f'LIME Fidelity (Predict): {accuracy_score(selected_model_predict_array, lime_predict_array):.4f}')
print(f'SHAP Fidelity (Predict): {accuracy_score(selected_model_predict_array, shap_predict_array):.4f}')

differing_indices = np.where(selected_model_predict_array != shap_predict_array)[0]
differing_indices

for id_to_test in differing_indices:
    print('LIME', selected_model_predict_proba_array[id_to_test, 1], lime_explanations_list[id_to_test].local_pred[0])
    print(int(lime_explanations_list[id_to_test].local_pred[0]>0.5))
    print('SHAP', selected_model_predict_proba_array[id_to_test, 1], exp_shap.expected_value[1] + np.sum(shap_values[id_to_test][:, 1]))
    print(int(exp_shap.expected_value[1] + np.sum(shap_values[id_to_test][:, 1])>0.5))

# lime_fidelity = np.mean([np.abs(selected_model_predict_proba_array[i, 0] - (lime_explanations_list[i].local_pred[0])) for i in range(len(x_test))])
# print(f'LIME Fidelity: {lime_fidelity:.2f}')

# # For SHAP, fidelity is usually high as it's designed to be an accurate representation of the model
# shap_fidelity = np.mean([np.abs(selected_model_predict_proba_array[i, 1] - (exp_shap.expected_value[0] + np.sum(shap_values[i][:, 0]))) for i in range(len(x_test))])
# print(f'SHAP Fidelity: {shap_fidelity:.2f}')

# # accuracy_score(selected_model.predict(X_test), np.argmax(shap_values, axis=1))
# from sklearn.metrics import accuracy_score

# lime_predict_array = np.array([1 if lime_explanations_list[i].local_pred[0]>0.5 else 0 for i in range(len(x_test))])
# shap_predict_array = np.array([0 if exp_shap.expected_value[0] + np.sum(shap_values[i][:, 0])>exp_shap.expected_value[0] + np.sum(shap_values[i][:, 1]) else 1 for i in range(len(x_test))])

# print(f'LIME Fidelity (Predict): {accuracy_score(selected_model_predict_array, lime_predict_array):.4f}')
# print(f'SHAP Fidelity (Predict): {accuracy_score(selected_model_predict_array, shap_predict_array):.4f}')

"""### EBM"""

ebm_local = ebm.explain_local(x_test, y_test, name='EBM')

# show(ebm.explain_local(x_test[554:555+1], y_test[554:555+1]), 0)
preserve(ebm_local, 2)
preserve(ebm_local, 3)

"""### TABNET"""

explain_tabnet_matrix, tabnet_masks = tbn.explain(x_test.values)

def get_tbn_local_graph(idx, feature_names):
    m = explain_tabnet_matrix[idx]>0
    ax = pd.Series(explain_tabnet_matrix[idx][m], index=np.array(feature_names)[m]).sort_values(ascending=True).plot.barh()
    ax.set_title("TabNet Feature Importance")
    ax.figure.tight_layout()
    plt.show()

get_tbn_local_graph(2, feature_names)
get_tbn_local_graph(3, feature_names)

fig, axs = plt.subplots(1, 3, figsize=(20,20))


for i in range(3):
    axs[i].imshow(tabnet_masks[i][2:4])
    axs[i].set_title(f"mask {i}")
    axs[i].set_xticklabels(labels = feature_names, rotation=45)

"""#### Simplicity"""

# https://link.springer.com/chapter/10.1007/978-3-031-20319-0_30
# Simplicity is the ability to choose only the necessary and sufficient features for explaining the prediction.

# Calculate simplicity
def calculate_simplicity(_values, threshold=0.05):
    simplicity_scores = []
    for instance_value in _values:
        abs_values = np.abs(instance_value)
        num_important_features = np.sum( abs_values > (max(abs_values) *threshold))
        simplicity_scores.append(num_important_features)
    return np.mean(simplicity_scores)


def get_simplicity_dict(name, values, threshold_list=[0.1, 0.05, 0.01]):
    d = {'Method': name}
    for threshold in threshold_list:
        d[threshold] = calculate_simplicity(values, threshold)
    return d

lime_feature_values = [list(zip(*lime_explanations_list[i].as_list()))[1] for i in range(len(x_test))]
ebm_local_scroes = [ebm_local.data(i)['scores'] for i in range(len(x_test))]

list_of_scores_dict = [get_simplicity_dict(name, values) for name, values in
                       [('LIME', lime_feature_values), ('SHAP', shap_values[:,:,0]), ('EBM', ebm_local_scroes),
                        ('TABNET', explain_tabnet_matrix)]]

_df_simplicity = pd.DataFrame(list_of_scores_dict)
_df_simplicity.set_index('Method', inplace=True)
_df_simplicity

# Common Top Feature Agreement

def retain_top_features(features, n=5):
    arr = np.abs(features)
    # Get the indices of the top n maximum values
    indices = np.argpartition(arr, -n)[-n:]

    # Create a mask
    mask = np.zeros_like(arr, dtype=bool)
    mask[indices] = True
    return np.where(mask, features, 0)

# lime_explanations_list[554].show_in_notebook(show_table=True)
# shap.plots.waterfall(exp_shap_values[554,:,output_to_explain], max_display=3)
def get_lime_feature_importance(lime_exp):
    feature_importance = {}
    for feature, sc in lime_exp.as_list():
        # print(feature)
        # Split feature by '<', '>', or '=' and take the first part as the feature name
        if feature.find('< ')>-1:
            feature = feature.split(' < ')[1]
        feature = feature.split(' > ')[0].strip()
        feature = feature.split(' <= ')[0].strip()
        for f in ['>', '<', '=']:
            if feature.find(f)>-1:
                print('error', feature)
        feature_importance[feature] = sc
    # print(feature_importance)
    # print([feature_importance.get(feature, 0) for feature in feature_names])
    return np.array([feature_importance.get(feature, 0) for feature in feature_names])

# lime_weights = dict(lime_explanations_list[0].as_list())
# lime_weights.get('Number_of_ANC_Visits', 0)
# pd.DataFrame([(shap_values[i][:, 0][1], get_lime_feature_importance(lime_explanations_list[i])[1]) for i in range(20)]).corr()
print(feature_names)

np.nonzero(retain_top_features(shap_values[2][:, 1], 2))[0], np.nonzero(retain_top_features(get_lime_feature_importance(lime_explanations_list[2]), 2))[0]

import numpy as np
from scipy.stats import ttest_rel, wilcoxon
from scipy.stats import shapiro

shap_val = lambda x, top_n=2: retain_top_features(shap_values[x][:, 1], top_n)
lime_val = lambda x, top_n=2: retain_top_features(get_lime_feature_importance(lime_explanations_list[x]), top_n)

def check_significant_differnce(dist1, dist2, top_n=2):
    data_process_1 = dist1
    data_process_2 = dist2

    # Shapiro-Wilk test
    # Shapiro-Wilk Test: If the p-value is less than 0.05, the null hypothesis that the data is normally distributed is rejected.
    for data in [data_process_1, data_process_2]:
        stat, p_value = shapiro(data)
        if not p_value<0.05:
            print('Alert: Normally distributed')
            print(f'Shapiro-Wilk test: Statistics={stat}, p-value={p_value}')


    # A suitable test in this context would be the paired t-test if the data is normally distributed or the Wilcoxon signed-rank test if the data is not normally distributed.
    # Paired t-test
    # t_statistic, p_value_ttest = ttest_rel(data_process_1, data_process_2)
    # print(f"Paired t-test: t-statistic = {t_statistic}, p-value = {p_value_ttest}")

    # Wilcoxon signed-rank test
    w_statistic, p_value_wilcoxon = wilcoxon(data_process_1, data_process_2)
    # print(f"Wilcoxon signed-rank test: w-statistic = {w_statistic}, p-value = {p_value_wilcoxon}")
    if p_value_wilcoxon<0.05:
        print('Alert: significant difference')

    # If the p-value is less than the chosen significance level (e.g., 0.05), you reject the null hypothesis and conclude that there is a significant difference between the means of the two processes.
    return p_value_wilcoxon

lime_shap_diff_p = [ check_significant_differnce(lime_val(i, top_n=2), shap_val(i, top_n=2), ) for i in range(len(x_test))]

"""#### Consistency"""

# Consistency measures how similar the explanations produced by different XAI methods are when applied to the same input data

shap_val = lambda x, top_n=2: retain_top_features(shap_values[x][:, 1], top_n)
lime_val = lambda x, top_n=2: retain_top_features(get_lime_feature_importance(lime_explanations_list[x]), top_n)
tabnet_val = lambda x, top_n=2: retain_top_features(explain_tabnet_matrix[x], top_n)
from scipy.stats import spearmanr

def get_consistency(method1, method2):
    numerator = 0
    divider = 0
    avg_sp_corr_list = []
    for n in range(1, 6): #only top 5 features: 1 feature is counted 5 five times, 2 four times,.. 5th only one time.

        # Compute Spearman's rank correlation coefficient
        spearman_corr_array = np.array([spearmanr(method1(i, top_n=n), method2(i, top_n=n))[0] for i in range(len(x_test))])
        avg_spearman_corr = spearman_corr_array.mean()
        avg_sp_corr_list.append(avg_spearman_corr)

    return np.array(avg_sp_corr_list).mean()

print(f'LIME, SHAP Consistency: {get_consistency(lime_val, shap_val):.2f}')
print(f'LIME, TABNET Consistency: {get_consistency(lime_val, tabnet_val):.2f}')
print(f'TABNET, SHAP Consistency: {get_consistency(tabnet_val, shap_val):.2f}')

"""#### Robustness"""

def add_noise(data, noise_level=0.01):
    noise = np.random.normal(0, noise_level, data.shape)
    return data + noise

x_test_noisy = add_noise(x_test)
display(x_test_noisy)

lime_explanations_list_noisy = [exp_lime.explain_instance(x_test_noisy.values[i], selected_model.predict_proba) for i in range(len(x_test))]
shap_values_noisy = exp_shap.shap_values(x_test_noisy)
ebm_local_noisy = ebm.explain_local(x_test_noisy, y_test, name='EBM')
explain_tabnet_matrix_noisy, tabnet_masks_noisy = tbn.explain(x_test_noisy.values)

# Function to calculate changes in explanations
def calculate_robustness(original, noisy):
    arr_org = np.array(original)
    arr_noisy = np.array(noisy)
    change_matrix = np.abs(arr_org - arr_noisy)
    divisor = max( [arr_org.max(), arr_noisy.max()] ) - min(  [arr_org.min(), arr_noisy.min()]  )  # max - min normalise
    return change_matrix.mean() / divisor  # divided in order to normalise between 0 to 1 (otherwise when the feature importance goes beyond 1 and under -1 such as in tabnet, ebm this won't normalise to 1)

def lime_robustness(original, noisy):
    means_list = []
    _max, _min = 0, 0
    for i in range(len(original)):
        d1, d2 = dict(original[i].as_list()), dict(noisy[i].as_list())
        # print(d1.keys())
        # print(d2.keys())
        v1, v2 = list(zip(*[[d1.get(f, 0), d2.get(f, 0)] for f in set(list(d1.keys())+list(d2.keys()))]))
        arr_org = np.array(v1)
        arr_noisy = np.array(v2)
        _max = max( [arr_org.max(), arr_noisy.max(), _max] )
        _min = min( [arr_org.min(), arr_noisy.min(), _min] )
        means_list.append(np.abs(arr_org - arr_noisy).mean())
    divisor = _max - _min
    return np.array(means_list).mean()/divisor # max - min normalise



print('Robustness')

print(f'LIME: {lime_robustness(lime_explanations_list, lime_explanations_list_noisy):.4f}')
print(f'SHAP: {calculate_robustness(shap_values, shap_values_noisy):.4f}')
_ebm_robustness = calculate_robustness([ebm_local.data(i)['scores'] for i in range(len(x_test))], [ebm_local_noisy.data(i)['scores'] for i in range(len(x_test))])
print(f'EBM: {_ebm_robustness:.4f}')
print(f'TABNET: {calculate_robustness(explain_tabnet_matrix, explain_tabnet_matrix_noisy):.4f}')

"""## Global

### PMI
"""

from sklearn.inspection import permutation_importance

start_time = time.time()
result = permutation_importance(
    selected_model, x_test, y_test, n_repeats=10, random_state=42, n_jobs=-1
)
elapsed_time = time.time() - start_time
print(f"Elapsed time to compute the importances: {elapsed_time:.3f} seconds")

selected_model_importances = pd.Series(result.importances_mean, index=feature_names).sort_values(ascending=True)

ax = selected_model_importances.plot.barh()
ax.set_title("Random Forest Feature Importance (PFI)")
ax.figure.tight_layout()

"""### TABNET"""

ax = pd.Series(tbn.feature_importances_, index=feature_names).sort_values(ascending=True).plot.barh()
ax.set_title("TabNet Feature Importance")
ax.figure.tight_layout()

"""### EBM"""

ebm_global = ebm.explain_global()
# show(ebm_global)

# Replace show with the preserve.

# ebm_global = ebm.explain_global(name='EBM')
# show(ebm_global)

# preserve(ebm_global, file_name='output/global-graph.html')
preserve(ebm_global)

"""### SHAP"""

shap.summary_plot(shap_values[:,:,0], x_test)
# shap.summary_plot(shap_values[:,:,0], X_test)

# f.savefig("summary_plot_CS.png", bbox_inches='tight', dpi=600)